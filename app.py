import streamlit as st
import os
import fitz  # PyMuPDF
from openai import OpenAI
from groq import Groq
from st_copy_to_clipboard import st_copy_to_clipboard
import time

# --- Configuration & Constants ---

# API Key Retrieval
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# --- IMPORTANT: Replace these with actual API model identifiers ---
MODEL_OPTIONS = {
    "Llama-3.3-70B (Groq)": {"id": "llama-3.3-70b-versatile", "provider": "groq"},
    "GPT-4.1 (OpenAI)": {"id": "gpt-4.1", "provider": "openai"},
    "Llama-3.1-8B-Instant (Groq)": {"id": "llama-3.1-8b-instant", "provider": "groq"}
}
DEFAULT_LLM_A_NAME = "Llama-3.3-70B (Groq)"
DEFAULT_LLM_B_NAME = "GPT-4.1 (OpenAI)"

# Task Definitions
TASK_PARAGRAPH_SUMMARY = "Paragraph Summary"
TASK_EXPLAIN_MAIN_SUBJECT = "Explain Main Subject"
TASK_OPTIONS = [TASK_PARAGRAPH_SUMMARY, TASK_EXPLAIN_MAIN_SUBJECT]
DEFAULT_TASK = TASK_PARAGRAPH_SUMMARY

# Prompts
PROMPT_SUMMARY_GENERATION = """
**Your Task:** Generate a high-quality, concise, and comprehensive paragraph summary of the provided [Source Text].

**Instructions for Crafting reputed Paragraph Summary:**
1.  **Understand Thoroughly:** Read the [Source Text] carefully to identify its central theme, main arguments, key findings, and essential supporting information.
2.  **Synthesize, Don't Just Extract:** Your summary should be a new piece of writing that expresses the core ideas of the source in your own words (as an LLM). Avoid simply copying and pasting sentences from the original text. The goal is true synthesis.
3.  **Accuracy is Paramount:** Ensure the summary accurately reflects the meaning and factual content of the [Source Text]. Do not introduce any information, interpretations, or opinions not explicitly present in the original.
4.  **Focus on Key Information:** Identify and include only the most important points necessary to convey the essence of the source. Omit minor details, redundant information, or tangential discussions.
5.  **Single, Coherent Paragraph:** The entire summary must be presented as a single, well-structured paragraph. It should flow logically, with clear transitions between ideas, making it easy for someone to understand the core message without having read the original text.
6.  **Conciseness:** Be as brief as possible while still covering the essential information. Every sentence should contribute to the summary's purpose.
7.  **Neutral and Objective Tone:** Unless the source text itself has a highly subjective tone that is central to its message, maintain a neutral and objective perspective.

**[Source Text]:**
\"\"\"
{source_text}
\"\"\"

**Paragraph Summary:**
"""

PROMPT_SUMMARY_VERIFICATION = """
**Your Role:** You are a meticulous Quality Assurance Editor, specializing in the evaluation of paragraph summaries.
**Your Task:**
Your goal is to assess the provided [Paragraph Summary] against the original [Source Text] to determine if it is a "good" summary according to the criteria below. Based on this assessment, you will output either a 'GREEN LIGHT' (if the summary is satisfactory) or a 'RED LIGHT' (if it has significant issues).

**Inputs:**
1.  **[Source Text]:** The full original text from which the summary was derived.
2.  **[Paragraph Summary]:** The single paragraph summary generated by another AI.

**Evaluation Criteria for a "Good Paragraph Summary":**
1.  **Accuracy:**
    * Does the summary faithfully represent the core information and meaning of the [Source Text]?
    * Does it avoid introducing any factual errors, new information not present in the source, or misrepresentations?
2.  **Key Information Coverage (Comprehensiveness for a Paragraph):**
    * Does the summary successfully capture the main idea(s) and the most crucial supporting points of the [Source Text] that are essential for understanding its essence?
    * Are any critical aspects or the central message of the source omitted, making the summary incomplete in its representation of the core content?
3.  **Conciseness and Focus:**
    * Is the summary appropriately concise and focused, avoiding unnecessary details, fluff, or redundant information that doesn't contribute to the main points?
    * Is it well-contained within a single paragraph without feeling overly dense or rushed?
4.  **Coherence and Readability:**
    * Is the paragraph well-written, with ideas flowing logically and sentences connecting smoothly?
    * Is it easy to understand for someone who has not read the original [Source Text]?
5.  **Neutrality and Objectivity:**
    * Does the summary maintain a neutral and objective tone, reflecting the information as presented in the [Source Text] (unless the source itself is clearly subjective and the summary needs to reflect that specific tone)?
6.  **Format Adherence:**
    * Is the summary correctly presented as a single, coherent paragraph?

**Output Instructions:**
* If the [Paragraph Summary] substantially meets **all** the above criteria to a good standard (minor stylistic preferences or very trivial, non-critical omissions might be acceptable, but there should be no significant flaws), respond with **only** the following words:
    `GREEN LIGHT`
* If the [Paragraph Summary] has **one or more significant flaws** in any of the evaluated criteria (especially concerning Accuracy or Key Information Coverage), respond with:
    `RED LIGHT`
    Immediately followed by a brief, bulleted list identifying the **primary reason(s)** for the 'RED LIGHT' (focus on the 1-3 most critical issues).

---
**Please begin your assessment.**
**[Source Text]:**
\"\"\"
{source_text}
\"\"\"
**[Paragraph Summary]:** \"\"\"
{step1_output}
\"\"\"
**Assessment Output:**
"""

PROMPT_EXPLAINER_TASK_FOR_LLM_A = """
You will be provided with a [Source Text]. Your first task is to identify the main subject or core concept discussed within this document.
Once you have identified this main subject/core concept, your second task is to explain it comprehensively based *only* on the information present in the [Source Text].
Use the following detailed structure and instructions for your explanation:

--- START OF EXPLAINER INSTRUCTIONS ---
You are an expert explainer. Your task is to break down the concept provided (which is the main subject of the document you've read) into clear, understandable parts for someone who is curious but not necessarily an expert.

# Instructions for the Explanation:
- Your explanation must be based on the information found within the [Source Text]. Do not introduce external knowledge unless it's for a general analogy clearly marked as such.
- Explain it step by step, avoiding jargon unless necessary and present in the [Source Text].
- If you use any technical terms from the [Source Text], define them simply based on their context in the document.
- Use analogies or metaphors where helpful to clarify concepts found in the text.
- Highlight not just *what* the main subject is, but *how* and *why* it works or is significant, according to the [Source Text].
- Structure your explanation clearly.

# Output Format for the Explanation:
**Concept:** [State the main subject/core concept you have identified from the Source Text here]

**What It Is:**
A simple definition of this concept, based on the Source Text.

**How It Works (or Key Aspects):**
A step-by-step explanation, mechanism, or key aspects of this concept, based on the Source Text.

**Why It Matters (according to the Source Text):**
Explain the significance, use cases, or implications of this concept as indicated in the Source Text.

**Analogy (Optional, if applicable and helps clarify):**
Use a metaphor or real-world comparison to help visualize the concept. If using an analogy that draws from general knowledge, clearly frame it as such.
--- END OF EXPLAINER INSTRUCTIONS ---

[Source Text]:
\"\"\"
{source_text}
\"\"\"

**Explanation of Main Subject:**
"""

PROMPT_EXPLANATION_VERIFICATION_FOR_LLM_B = """
**Your Role:** You are a Factual Accuracy Reviewer for AI-generated explanations.
**Your Task:**
Critically evaluate the provided [Generated Explanation] against the original [Source Text]. Your primary goal is to determine if the factual assertions within the explanation (specifically in its "What It Is," "How It Works (or Key Aspects)," and "Why It Matters" sections) are accurate and directly supported by the [Source Text].

**Inputs:**
1.  **[Source Text]:** The original document.
2.  **[Generated Explanation]:** The explanation produced by another AI. It should identify a concept and explain it in a structured format.

**Evaluation Criteria (Focus on Factual Accuracy from Source Text):**

1.  **Accuracy of "Concept" Identification:** Does the identified "Concept" in the explanation accurately reflect a main subject or core concept of the [Source Text]? (Minor issue if debatable but plausible; Major if clearly off-topic).
2.  **Accuracy of "What It Is":** Is the definition/description provided for the concept factually accurate and consistent with the [Source Text]?
3.  **Accuracy of "How It Works (or Key Aspects)":** Are the mechanisms, processes, or key aspects described factually accurate and consistent with the [Source Text]?
4.  **Accuracy of "Why It Matters":** Are the significance, use cases, or implications stated factually accurate and supported by the [Source Text]?
5.  **No Unsupported External Information:** Does the explanation (outside of a clearly marked optional analogy) avoid introducing significant factual information not present in or directly inferable from the [Source Text]?

**Output Instructions:**

* If the "Concept" is relevant, and the "What It Is," "How It Works (or Key Aspects)," and "Why It Matters" sections of the [Generated Explanation] are substantially factually accurate and well-supported by the [Source Text] (minor phrasing differences are acceptable, but no significant factual contradictions or unsupported assertions), respond with **only** the following words:
    `GREEN LIGHT`

* If the identified "Concept" is largely irrelevant to the source text, OR if there are significant factual inaccuracies, misrepresentations, or assertions not supported by the [Source Text] in the core explanation sections, respond with:
    `RED LIGHT`
    Immediately followed by a brief, bulleted list identifying the primary factual issue(s). Focus on the 1-3 most critical inaccuracies or relevance issues.

---
**Please begin your assessment.**
**[Source Text]:**
\"\"\"
{source_text}
\"\"\"
**[Generated Explanation]:**
\"\"\"
{step1_output} 
\"\"\"
**Assessment Output:**
"""


# --- Core Functions ---

def extract_text_from_pdf(uploaded_file_obj):
    """Extracts text from an uploaded PDF file object using PyMuPDF/fitz."""
    text = ""
    try:
        pdf_bytes = uploaded_file_obj.getvalue()
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text += page.get_text("text") + "\n" 
    except Exception as e:
        return None, f"Error extracting text: {e}"
    if not text.strip():
        return None, "No text content found in PDF."
    return text, None

def call_openai_api(model_id, messages, temperature=0.3, max_tokens=2048): # Increased max_tokens for explanation
    """Helper function to call OpenAI API using client.chat.completions.create."""
    if not OPENAI_API_KEY:
        return None, "OpenAI API key not found. Please set the OPENAI_API_KEY environment variable."
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature, 
            max_tokens=max_tokens    
        )
        return completion.choices[0].message.content.strip(), None
    except Exception as e:
        return None, f"OpenAI API Error (using chat.completions.create): {e}"

def call_groq_api(model_id, messages, temperature=0.3, max_tokens=2048): # Increased max_tokens for explanation
    """Helper function to call Groq API."""
    if not GROQ_API_KEY:
        return None, "Groq API key not found. Please set the GROQ_API_KEY environment variable."
    try:
        client = Groq(api_key=GROQ_API_KEY)
        completion = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return completion.choices[0].message.content.strip(), None
    except Exception as e:
        return None, f"Groq API Error: {e}"

def get_llm_response(source_text, prompt_template_str, llm_choice_name, step1_output_for_step2=None):
    """
    Gets response from the selected LLM.
    'source_text' is the original PDF text.
    'prompt_template_str' is the string of the prompt to use.
    'llm_choice_name' is the user-selected LLM name.
    'step1_output_for_step2' is the output from LLM A, used as input for LLM B's prompt.
    Returns (response_text, error_message)
    """
    model_info = MODEL_OPTIONS.get(llm_choice_name)
    if not model_info:
        return None, f"Invalid LLM choice: {llm_choice_name}"

    model_id = model_info["id"]
    provider = model_info["provider"]

    if step1_output_for_step2: # This is for Step 2 (Verification)
        filled_prompt = prompt_template_str.format(source_text=source_text, step1_output=step1_output_for_step2)
    else: # This is for Step 1 (Generation/Explanation)
        filled_prompt = prompt_template_str.format(source_text=source_text)
    
    messages_for_api = [{"role": "user", "content": filled_prompt}]
    
    # Max tokens might need to be different for summarization vs explanation
    # For now, using a general higher value for explanations.
    # Paragraph summary prompt itself asks for conciseness.
    api_temperature = 0.3 
    if "explain" in prompt_template_str.lower() or "explainer" in prompt_template_str.lower() : # Crude check for explainer prompt
        api_max_tokens = 2048 # Allow more tokens for detailed explanations
    else:
        api_max_tokens = 1024 # Default for summaries

    if provider == "openai":
        return call_openai_api(model_id, messages_for_api, temperature=api_temperature, max_tokens=api_max_tokens)
    elif provider == "groq":
        return call_groq_api(model_id, messages_for_api, temperature=api_temperature, max_tokens=api_max_tokens)
    else:
        return None, f"Provider '{provider}' not configured for LLM choice '{llm_choice_name}'."

# --- Streamlit UI ---

st.set_page_config(layout="wide", page_title="Two-Step PDF Processor")
st.title("📑 Two-Step PDF Processor")
st.markdown("Upload PDFs, choose a task (summarize or explain), generate output, and verify it using your choice of LLMs.")

if 'results' not in st.session_state:
    st.session_state.results = []
if 'processing_started' not in st.session_state:
    st.session_state.processing_started = False

with st.sidebar:
    st.header("⚙️ Controls")
    uploaded_files = st.file_uploader(
        "Upload PDF files",
        type="pdf",
        accept_multiple_files=True,
        help="Upload one or more PDF files."
    )

    selected_task = st.selectbox(
        "Select Task:",
        options=TASK_OPTIONS,
        index=TASK_OPTIONS.index(DEFAULT_TASK),
        help="Choose the operation to perform on the PDFs."
    )

    st.subheader("Select LLMs for Processing:")
    llm_a_choice_name = st.selectbox(
        f"Step 1: {selected_task} with:",
        options=list(MODEL_OPTIONS.keys()),
        index=list(MODEL_OPTIONS.keys()).index(DEFAULT_LLM_A_NAME) if DEFAULT_LLM_A_NAME in MODEL_OPTIONS else 0,
        help=f"Choose the LLM to perform '{selected_task}'."
    )
    llm_b_choice_name = st.selectbox(
        "Step 2: Verify Output with:",
        options=list(MODEL_OPTIONS.keys()),
        index=list(MODEL_OPTIONS.keys()).index(DEFAULT_LLM_B_NAME) if DEFAULT_LLM_B_NAME in MODEL_OPTIONS else 0,
        help="Choose the LLM to verify the output from Step 1."
    )

    if st.button(f"Process Uploaded PDFs with '{selected_task}' Task", type="primary", disabled=not uploaded_files):
        st.session_state.results = [] 
        st.session_state.processing_started = True
        st.session_state.current_task_for_results = selected_task # Store task type for display
    
    if st.session_state.results and st.session_state.processing_started: 
        if st.button("Clear Results & Files"):
            st.session_state.results = []
            st.session_state.processing_started = False
            st.rerun()

if st.session_state.processing_started and uploaded_files:
    api_keys_ok = True
    # Consolidate API key checks
    providers_in_use = set()
    if llm_a_choice_name in MODEL_OPTIONS: providers_in_use.add(MODEL_OPTIONS[llm_a_choice_name]["provider"])
    if llm_b_choice_name in MODEL_OPTIONS: providers_in_use.add(MODEL_OPTIONS[llm_b_choice_name]["provider"])

    if "groq" in providers_in_use and not GROQ_API_KEY:
        st.error("Groq API key is missing. Please set the GROQ_API_KEY environment variable.")
        api_keys_ok = False
    if "openai" in providers_in_use and not OPENAI_API_KEY:
        st.error("OpenAI API key is missing. Please set the OPENAI_API_KEY environment variable.")
        api_keys_ok = False

    if not api_keys_ok:
        st.warning("Processing cannot start due to missing API keys.")
        st.session_state.processing_started = False 
    else:
        total_files = len(uploaded_files)
        progress_bar_placeholder = st.empty() 
        status_text_placeholder = st.empty()   

        with st.spinner(f"Processing {total_files} PDF(s) for '{st.session_state.current_task_for_results}' task... Please wait."):
            for i, uploaded_file in enumerate(uploaded_files):
                current_file_result = {
                    "filename": uploaded_file.name, 
                    "task_performed": st.session_state.current_task_for_results,
                    "step1_output": None, 
                    "step2_verification": None, 
                    "error_message": None,
                    "extracted_text_snippet": None, 
                    "time_step1_sec": None, 
                    "time_step2_sec": None  
                }
                
                progress_percentage = (i + 1) / total_files
                progress_bar_placeholder.progress(progress_percentage)
                status_text_placeholder.text(f"Processing file {i+1}/{total_files}: {uploaded_file.name}...")
                
                try:
                    status_text_placeholder.text(f"({i+1}/{total_files}) Extracting text from: {uploaded_file.name}")
                    source_text, extraction_error = extract_text_from_pdf(uploaded_file)
                    if extraction_error:
                        current_file_result["error_message"] = extraction_error
                        st.session_state.results.append(current_file_result)
                        continue 
                    current_file_result["extracted_text_snippet"] = (source_text[:500] + "...") if source_text and len(source_text) > 500 else source_text

                    # --- Determine Prompts based on selected_task ---
                    if st.session_state.current_task_for_results == TASK_PARAGRAPH_SUMMARY:
                        prompt_step1 = PROMPT_SUMMARY_GENERATION
                        prompt_step2 = PROMPT_SUMMARY_VERIFICATION
                        step1_output_header = "Generated Paragraph Summary"
                    elif st.session_state.current_task_for_results == TASK_EXPLAIN_MAIN_SUBJECT:
                        prompt_step1 = PROMPT_EXPLAINER_TASK_FOR_LLM_A
                        prompt_step2 = PROMPT_EXPLANATION_VERIFICATION_FOR_LLM_B
                        step1_output_header = "Generated Explanation of Main Subject"
                    else:
                        current_file_result["error_message"] = "Invalid task selected."
                        st.session_state.results.append(current_file_result)
                        continue
                    
                    # --- Step 1: Task Execution (LLM A) with Timing ---
                    status_text_placeholder.text(f"({i+1}/{total_files}) Performing Step 1 ({st.session_state.current_task_for_results}) for: {uploaded_file.name} using {llm_a_choice_name}")
                    start_time_step1 = time.perf_counter()
                    step1_output, step1_error = get_llm_response(source_text, prompt_step1, llm_a_choice_name)
                    end_time_step1 = time.perf_counter()
                    current_file_result["time_step1_sec"] = round(end_time_step1 - start_time_step1, 2)

                    if step1_error:
                        current_file_result["error_message"] = f"Step 1 ({st.session_state.current_task_for_results}) error: {step1_error}"
                        st.session_state.results.append(current_file_result)
                        continue
                    current_file_result["step1_output"] = step1_output

                    # --- Step 2: Verification (LLM B) with Timing ---
                    status_text_placeholder.text(f"({i+1}/{total_files}) Performing Step 2 (Verification) for: {uploaded_file.name} using {llm_b_choice_name}")
                    start_time_step2 = time.perf_counter()
                    verification_output, verification_error = get_llm_response(source_text, prompt_step2, llm_b_choice_name, step1_output_for_step2=step1_output)
                    end_time_step2 = time.perf_counter()
                    current_file_result["time_step2_sec"] = round(end_time_step2 - start_time_step2, 2)

                    if verification_error:
                        current_file_result["error_message"] = f"Step 2 (Verification) error: {verification_error}"
                        current_file_result["step2_verification"] = "Verification failed." 
                        st.session_state.results.append(current_file_result)
                        continue
                    current_file_result["step2_verification"] = verification_output
                
                except Exception as e:
                    current_file_result["error_message"] = f"Unexpected error processing {uploaded_file.name}: {str(e)}"
                
                st.session_state.results.append(current_file_result)

            status_text_placeholder.success(f"All files processed for '{st.session_state.current_task_for_results}' task!")
            progress_bar_placeholder.empty() 

if st.session_state.results:
    st.markdown("---")
    st.header("📊 Processing Results")
    
    # Retrieve task type used for this batch of results for consistent display headers
    # Assuming all results in current st.session_state.results are from the same task batch
    # This relies on st.session_state.current_task_for_results being set when processing starts
    task_performed_for_display = st.session_state.get("current_task_for_results", "N/A")
    
    llm_a_display_name = llm_a_choice_name # Capture from sidebar selection
    llm_b_display_name = llm_b_choice_name # Capture from sidebar selection

    downloadable_content = "" 

    for i, res in enumerate(st.session_state.results): 
        expander_title = f"Results for: {res['filename']} (Task: {res.get('task_performed', task_performed_for_display)})"
        if res["error_message"]:
            expander_title += " (Error)"
        
        with st.expander(expander_title, expanded=False):
            downloadable_content += f"--- Results for: {res['filename']} ---\n"
            downloadable_content += f"Task Performed: {res.get('task_performed', task_performed_for_display)}\n\n"
            
            if res["error_message"]:
                st.error(f"Error: {res['error_message']}")
                downloadable_content += f"Error: {res['error_message']}\n\n"
            
            step1_output_header_display = "Step 1 Output"
            if res.get('task_performed', task_performed_for_display) == TASK_PARAGRAPH_SUMMARY:
                step1_output_header_display = f"Generated Paragraph Summary (by {llm_a_display_name})"
            elif res.get('task_performed', task_performed_for_display) == TASK_EXPLAIN_MAIN_SUBJECT:
                step1_output_header_display = f"Generated Explanation (by {llm_a_display_name})"


            if res["step1_output"]:
                st.subheader(step1_output_header_display)
                if res["time_step1_sec"] is not None:
                    st.caption(f"Step 1 Time: {res['time_step1_sec']:.2f} seconds")
                    downloadable_content += f"Step 1 Time: {res['time_step1_sec']:.2f} seconds\n"
                st.markdown(res["step1_output"]) # LLM output might contain markdown
                downloadable_content += f"{step1_output_header_display}:\n{res['step1_output']}\n\n"
            elif not res["error_message"]:
                st.info("Step 1 output could not be generated for this file.")
                downloadable_content += "Step 1 output could not be generated for this file.\n\n"

            if res["step2_verification"]:
                st.subheader(f"Step 2 Verification (by {llm_b_display_name}):")
                if res["time_step2_sec"] is not None:
                    st.caption(f"Step 2 Time: {res['time_step2_sec']:.2f} seconds")
                    downloadable_content += f"Step 2 Time: {res['time_step2_sec']:.2f} seconds\n"

                downloadable_content += f"Step 2 Verification (by {llm_b_display_name}):\n"
                if "GREEN LIGHT" in res["step2_verification"].upper(): 
                    st.success("✅ GREEN LIGHT")
                    downloadable_content += "GREEN LIGHT\n"
                elif "RED LIGHT" in res["step2_verification"].upper(): 
                    st.error("❌ RED LIGHT")
                    downloadable_content += "RED LIGHT\n"
                    try:
                        reasons_part = res["step2_verification"].upper().split("RED LIGHT", 1)[1].strip()
                        if reasons_part:
                            st.markdown("**Reasons:**")
                            downloadable_content += "Reasons:\n"
                            reason_lines = reasons_part.split('\n')
                            for line in reason_lines:
                                clean_line = line.strip()
                                if clean_line.startswith("*") or clean_line.startswith("-"):
                                    st.markdown(clean_line)
                                    downloadable_content += f"{clean_line}\n"
                                elif clean_line: 
                                    st.markdown(f"* {clean_line}")
                                    downloadable_content += f"* {clean_line}\n"
                    except IndexError: 
                        pass 
                else: 
                    st.info(res["step2_verification"]) 
                    downloadable_content += f"{res['step2_verification']}\n"
                downloadable_content += "\n"

            elif not res["error_message"] and res["step1_output"]: 
                 st.info("Step 1 output was generated but Step 2 (Verification) did not complete or returned no output.")
                 downloadable_content += "Step 1 output was generated but Step 2 (Verification) did not complete or returned no output.\n\n"
            
            downloadable_content += "\n\n" # Extra space between file results in download

    if downloadable_content: 
        st_copy_to_clipboard(downloadable_content, "Copy All Results to Clipboard")
        st.caption("Click the button above to copy all results to your clipboard.")


st.markdown("---")
st.caption("Developed with Streamlit. Ensure API keys (GROQ_API_KEY, OPENAI_API_KEY) are set as environment variables.")
st.caption(f"Using models (check API docs for exact IDs): {', '.join(MODEL_OPTIONS.keys())}")
st.caption("Ensure you have `streamlit-copy-to-clipboard` installed: `pip install streamlit-copy-to-clipboard`")

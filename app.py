import streamlit as st
import os
import fitz  # PyMuPDF
from openai import OpenAI
from groq import Groq
from st_copy_to_clipboard import st_copy_to_clipboard # Corrected import
import time 

# --- Configuration & Constants ---

# API Key Retrieval
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# --- IMPORTANT: Replace these with actual API model identifiers ---
MODEL_OPTIONS = {
    "Llama-3.3-70B (Groq)": {"id": "llama3.3-70b-versatile", "provider": "groq"}, # Example Groq ID for Llama3 70B
    "GPT-4.1 (OpenAI)": {"id": "gpt-4.1", "provider": "openai"} # Example OpenAI ID (e.g., gpt-4o, gpt-4-turbo)
}
DEFAULT_LLM_A_NAME = "Llama-3.3-70B (Groq)"
DEFAULT_LLM_B_NAME = "GPT-4.1 (OpenAI)"


# Prompts
PROMPT_SUMMARY_GENERATION = """
**Your Task:** Generate a high-quality, concise, and comprehensive paragraph summary of the provided [Source Text].

**Instructions for Crafting reputed Paragraph Summary:**

1.  **Understand Thoroughly:** Read the [Source Text] carefully to identify its central theme, main arguments, key findings, and essential supporting information.
2.  **Synthesize, Don't Just Extract:** Your summary should be a new piece of writing that expresses the core ideas of the source in your own words (as an LLM). Avoid simply copying and pasting sentences from the original text. The goal is true synthesis.
3.  **Accuracy is Paramount:** Ensure the summary accurately reflects the meaning and factual content of the [Source Text]. Do not introduce any information, interpretations, or opinions not explicitly present in the original.
4.  **Focus on Key Information:** Identify and include only the most important points necessary to convey the essence of the source. Omit minor details, redundant information, or tangential discussions.
5.  **Single, Coherent Paragraph:** The entire summary must be presented as a single, well-structured paragraph. It should flow logically, with clear transitions between ideas, making it easy for someone to understand the core message without having read the original text.
6.  **Conciseness:** Be as brief as possible while still covering the essential information. Every sentence should contribute to the summary's purpose.
7.  **Neutral and Objective Tone:** Unless the source text itself has a highly subjective tone that is central to its message, maintain a neutral and objective perspective.

**[Source Text]:**
\"\"\"
{source_text}
\"\"\"

**Paragraph Summary:**
"""

PROMPT_SUMMARY_VERIFICATION = """
**Your Role:** You are a meticulous Quality Assurance Editor, specializing in the evaluation of paragraph summaries.

**Your Task:**
Your goal is to assess the provided [Paragraph Summary] against the original [Source Text] to determine if it is a "good" summary according to the criteria below. Based on this assessment, you will output either a 'GREEN LIGHT' (if the summary is satisfactory) or a 'RED LIGHT' (if it has significant issues).

**Inputs:**
1.  **[Source Text]:** The full original text from which the summary was derived.
2.  **[Paragraph Summary]:** The single paragraph summary generated by another AI.

**Evaluation Criteria for a "Good Paragraph Summary":**

1.  **Accuracy:**
    * Does the summary faithfully represent the core information and meaning of the [Source Text]?
    * Does it avoid introducing any factual errors, new information not present in the source, or misrepresentations?
2.  **Key Information Coverage (Comprehensiveness for a Paragraph):**
    * Does the summary successfully capture the main idea(s) and the most crucial supporting points of the [Source Text] that are essential for understanding its essence?
    * Are any critical aspects or the central message of the source omitted, making the summary incomplete in its representation of the core content?
3.  **Conciseness and Focus:**
    * Is the summary appropriately concise and focused, avoiding unnecessary details, fluff, or redundant information that doesn't contribute to the main points?
    * Is it well-contained within a single paragraph without feeling overly dense or rushed?
4.  **Coherence and Readability:**
    * Is the paragraph well-written, with ideas flowing logically and sentences connecting smoothly?
    * Is it easy to understand for someone who has not read the original [Source Text]?
5.  **Neutrality and Objectivity:**
    * Does the summary maintain a neutral and objective tone, reflecting the information as presented in the [Source Text] (unless the source itself is clearly subjective and the summary needs to reflect that specific tone)?
6.  **Format Adherence:**
    * Is the summary correctly presented as a single, coherent paragraph?

**Output Instructions:**

* If the [Paragraph Summary] substantially meets **all** the above criteria to a good standard (minor stylistic preferences or very trivial, non-critical omissions might be acceptable, but there should be no significant flaws), respond with **only** the following words:
    `GREEN LIGHT`

* If the [Paragraph Summary] has **one or more significant flaws** in any of the evaluated criteria (especially concerning Accuracy or Key Information Coverage), respond with:
    `RED LIGHT`
    Immediately followed by a brief, bulleted list identifying the **primary reason(s)** for the 'RED LIGHT' (focus on the 1-3 most critical issues). For example:
    * `RED LIGHT`
        * Accuracy: The summary misrepresents the study's main conclusion.
        * Omission: Fails to mention the primary solution proposed in the text.

---

**Please begin your assessment.**

**[Source Text]:**
\"\"\"
{source_text}
\"\"\"

**[Paragraph Summary]:**
\"\"\"
{summary_text}
\"\"\"

**Assessment Output:**
"""

# --- Core Functions ---

def extract_text_from_pdf(uploaded_file_obj):
    """Extracts text from an uploaded PDF file object using PyMuPDF/fitz."""
    text = ""
    try:
        pdf_bytes = uploaded_file_obj.getvalue()
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text += page.get_text("text") + "\n" 
    except Exception as e:
        return None, f"Error extracting text: {e}"
    if not text.strip():
        return None, "No text content found in PDF."
    return text, None

def call_openai_api(model_id, messages, temperature=0.3, max_tokens=1500):
    """Helper function to call OpenAI API using client.chat.completions.create."""
    if not OPENAI_API_KEY:
        return None, "OpenAI API key not found. Please set the OPENAI_API_KEY environment variable."
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature, 
            max_tokens=max_tokens    
        )
        return completion.choices[0].message.content.strip(), None
    except Exception as e:
        return None, f"OpenAI API Error (using chat.completions.create): {e}"

def call_groq_api(model_id, messages, temperature=0.3, max_tokens=1500):
    """Helper function to call Groq API."""
    if not GROQ_API_KEY:
        return None, "Groq API key not found. Please set the GROQ_API_KEY environment variable."
    try:
        client = Groq(api_key=GROQ_API_KEY)
        completion = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return completion.choices[0].message.content.strip(), None
    except Exception as e:
        return None, f"Groq API Error: {e}"

def get_llm_response(text_input, prompt_template, llm_choice_name, summary_text_input=None):
    """
    Gets response from the selected LLM.
    Returns (response_text, error_message)
    """
    model_info = MODEL_OPTIONS.get(llm_choice_name)
    if not model_info:
        return None, f"Invalid LLM choice: {llm_choice_name}"

    model_id = model_info["id"]
    provider = model_info["provider"]

    if summary_text_input: 
        filled_prompt = prompt_template.format(source_text=text_input, summary_text=summary_text_input)
    else: 
        filled_prompt = prompt_template.format(source_text=text_input)
    
    messages_for_api = [{"role": "user", "content": filled_prompt}]
    
    api_temperature = 0.3 
    api_max_tokens = 1500

    if provider == "openai":
        return call_openai_api(model_id, messages_for_api, temperature=api_temperature, max_tokens=api_max_tokens)
    elif provider == "groq":
        return call_groq_api(model_id, messages_for_api, temperature=api_temperature, max_tokens=api_max_tokens)
    else:
        return None, f"Provider '{provider}' not configured for LLM choice '{llm_choice_name}'."

# --- Streamlit UI ---

st.set_page_config(layout="wide", page_title="Two-Step PDF Summarizer")
st.title("üìë Two-Step PDF Summarizer")
st.markdown("Upload PDFs, generate summaries, and verify them using your choice of LLMs. Results will appear below after processing.")

if 'results' not in st.session_state:
    st.session_state.results = []
if 'processing_started' not in st.session_state:
    st.session_state.processing_started = False


with st.sidebar:
    st.header("‚öôÔ∏è Controls")
    uploaded_files = st.file_uploader(
        "Upload PDF files",
        type="pdf",
        accept_multiple_files=True,
        help="Upload one or more PDF files to be summarized and verified."
    )

    st.subheader("Select LLMs for Processing:")
    llm_a_choice_name = st.selectbox(
        "Step 1: Generate Summary with:",
        options=list(MODEL_OPTIONS.keys()),
        index=list(MODEL_OPTIONS.keys()).index(DEFAULT_LLM_A_NAME),
        help="Choose the LLM to generate the initial paragraph summary."
    )
    llm_b_choice_name = st.selectbox(
        "Step 2: Verify Summary with:",
        options=list(MODEL_OPTIONS.keys()),
        index=list(MODEL_OPTIONS.keys()).index(DEFAULT_LLM_B_NAME),
        help="Choose the LLM to verify the summary and provide a Green/Red Light."
    )

    if st.button("Summarize Uploaded PDFs", type="primary", disabled=not uploaded_files):
        st.session_state.results = [] 
        st.session_state.processing_started = True
    
    if st.session_state.results and st.session_state.processing_started: 
        if st.button("Clear Results & Files"):
            st.session_state.results = []
            st.session_state.processing_started = False
            st.rerun()

if st.session_state.processing_started and uploaded_files:
    api_keys_ok = True
    if (MODEL_OPTIONS[llm_a_choice_name]["provider"] == "groq" or \
        MODEL_OPTIONS[llm_b_choice_name]["provider"] == "groq") and not GROQ_API_KEY:
        st.error("Groq API key is missing. Please set the GROQ_API_KEY environment variable.")
        api_keys_ok = False
    if (MODEL_OPTIONS[llm_a_choice_name]["provider"] == "openai" or \
        MODEL_OPTIONS[llm_b_choice_name]["provider"] == "openai") and not OPENAI_API_KEY:
        st.error("OpenAI API key is missing. Please set the OPENAI_API_KEY environment variable.")
        api_keys_ok = False

    if not api_keys_ok:
        st.warning("Processing cannot start due to missing API keys.")
        st.session_state.processing_started = False 
    else:
        total_files = len(uploaded_files)
        progress_bar_placeholder = st.empty() 
        status_text_placeholder = st.empty()   

        with st.spinner(f"Processing {total_files} PDF(s)... Please wait."):
            for i, uploaded_file in enumerate(uploaded_files):
                current_file_result = {
                    "filename": uploaded_file.name, 
                    "summary": None, 
                    "verification": None, 
                    "error_message": None,
                    "extracted_text_snippet": None, 
                    "time_step1_sec": None, 
                    "time_step2_sec": None  
                }
                
                progress_percentage = (i + 1) / total_files
                progress_bar_placeholder.progress(progress_percentage)
                status_text_placeholder.text(f"Processing file {i+1}/{total_files}: {uploaded_file.name}...")
                
                try:
                    status_text_placeholder.text(f"({i+1}/{total_files}) Extracting text from: {uploaded_file.name}")
                    source_text, extraction_error = extract_text_from_pdf(uploaded_file)
                    if extraction_error:
                        current_file_result["error_message"] = extraction_error
                        st.session_state.results.append(current_file_result)
                        continue 
                    current_file_result["extracted_text_snippet"] = (source_text[:500] + "...") if source_text and len(source_text) > 500 else source_text

                    status_text_placeholder.text(f"({i+1}/{total_files}) Generating summary for: {uploaded_file.name} using {llm_a_choice_name}")
                    start_time_step1 = time.perf_counter()
                    summary, summary_error = get_llm_response(source_text, PROMPT_SUMMARY_GENERATION, llm_a_choice_name)
                    end_time_step1 = time.perf_counter()
                    current_file_result["time_step1_sec"] = round(end_time_step1 - start_time_step1, 2)

                    if summary_error:
                        current_file_result["error_message"] = f"Summary generation error: {summary_error}"
                        st.session_state.results.append(current_file_result)
                        continue
                    current_file_result["summary"] = summary

                    status_text_placeholder.text(f"({i+1}/{total_files}) Verifying summary for: {uploaded_file.name} using {llm_b_choice_name}")
                    start_time_step2 = time.perf_counter()
                    verification_output, verification_error = get_llm_response(source_text, PROMPT_SUMMARY_VERIFICATION, llm_b_choice_name, summary_text_input=summary)
                    end_time_step2 = time.perf_counter()
                    current_file_result["time_step2_sec"] = round(end_time_step2 - start_time_step2, 2)

                    if verification_error:
                        current_file_result["error_message"] = f"Summary verification error: {verification_error}"
                        current_file_result["verification"] = "Verification failed." 
                        st.session_state.results.append(current_file_result)
                        continue
                    current_file_result["verification"] = verification_output
                
                except Exception as e:
                    current_file_result["error_message"] = f"Unexpected error processing {uploaded_file.name}: {str(e)}"
                
                st.session_state.results.append(current_file_result)

            status_text_placeholder.success("All files processed!")
            progress_bar_placeholder.empty() 

if st.session_state.results:
    st.markdown("---")
    st.header("üìä Processing Results")
    
    downloadable_content = "" # Renamed to reflect its purpose for copy/download

    for i, res in enumerate(st.session_state.results): 
        expander_title = f"Results for: {res['filename']}"
        if res["error_message"]:
            expander_title += " (Error)"
        
        with st.expander(expander_title, expanded=False):
            # Accumulate content for copying/downloading
            current_file_content_for_export = f"--- Results for: {res['filename']} ---\n\n"
            
            if res["error_message"]:
                st.error(f"Error: {res['error_message']}")
                current_file_content_for_export += f"Error: {res['error_message']}\n\n"
            
            if res["summary"]:
                st.subheader(f"Generated Summary (by {llm_a_choice_name}):")
                if res["time_step1_sec"] is not None:
                    st.caption(f"Generation Time: {res['time_step1_sec']:.2f} seconds")
                    current_file_content_for_export += f"Generation Time (Step 1): {res['time_step1_sec']:.2f} seconds\n"
                st.markdown(res["summary"])
                current_file_content_for_export += f"Generated Summary (by {llm_a_choice_name}):\n{res['summary']}\n\n"
            elif not res["error_message"]:
                st.info("Summary could not be generated for this file.")
                current_file_content_for_export += "Summary could not be generated for this file.\n\n"

            if res["verification"]:
                st.subheader(f"Summary Verification (by {llm_b_choice_name}):")
                if res["time_step2_sec"] is not None:
                    st.caption(f"Verification Time: {res['time_step2_sec']:.2f} seconds")
                    current_file_content_for_export += f"Verification Time (Step 2): {res['time_step2_sec']:.2f} seconds\n"

                current_file_content_for_export += f"Summary Verification (by {llm_b_choice_name}):\n"
                if "GREEN LIGHT" in res["verification"].upper(): 
                    st.success("‚úÖ GREEN LIGHT")
                    current_file_content_for_export += "GREEN LIGHT\n"
                elif "RED LIGHT" in res["verification"].upper(): 
                    st.error("‚ùå RED LIGHT")
                    current_file_content_for_export += "RED LIGHT\n"
                    try:
                        reasons_part = res["verification"].upper().split("RED LIGHT", 1)[1].strip()
                        if reasons_part:
                            st.markdown("**Reasons:**")
                            current_file_content_for_export += "Reasons:\n"
                            reason_lines = reasons_part.split('\n')
                            for line in reason_lines:
                                clean_line = line.strip()
                                if clean_line.startswith("*") or clean_line.startswith("-"):
                                    st.markdown(clean_line)
                                    current_file_content_for_export += f"{clean_line}\n"
                                elif clean_line: 
                                    st.markdown(f"* {clean_line}")
                                    current_file_content_for_export += f"* {clean_line}\n"
                    except IndexError: 
                        pass 
                else: 
                    st.info(res["verification"]) 
                    current_file_content_for_export += f"{res['verification']}\n"
                current_file_content_for_export += "\n"

            elif not res["error_message"] and res["summary"]: 
                 st.info("Summary was generated but verification step did not complete or returned no output.")
                 current_file_content_for_export += "Summary was generated but verification step did not complete or returned no output.\n\n"
            
            downloadable_content += current_file_content_for_export + "\n\n" 

    if downloadable_content: # Check if there's any content to copy
        # Use st_copy_to_clipboard instead of st.download_button
        st_copy_to_clipboard(downloadable_content, "Copy All Results to Clipboard")
        st.caption("Click the button above to copy all results to your clipboard.")


st.markdown("---")
st.caption("Developed with Streamlit. Ensure API keys (GROQ_API_KEY, OPENAI_API_KEY) are set as environment variables.")
st.caption(f"Using models (check API docs for exact IDs): {', '.join(MODEL_OPTIONS.keys())}")
st.caption("Ensure you have `streamlit-copy-to-clipboard` installed: `pip install streamlit-copy-to-clipboard`")

